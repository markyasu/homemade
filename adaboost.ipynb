{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a Decision Stump\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import scipy.stats as sps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data and define the column labels\n",
    "dataset = pd.read_csv('combinedDataSet.csv')\n",
    "\n",
    "#dataset = dataset.sample(frac=1)\n",
    "dataset.columns = ['Smoking', 'Gender', 'Age', 'Height', 'Weight', 'DiabeticStatus', 'HR', 'HRRange', 'pNN50', 'RMSSD', 'stdNN', 'MeanSE', 'VarSE', 'IQRSE', 'SkewSE', 'VarLogE', 'IQRLogE', 'stdKTE', 'MeanKTE', 'IQRKTE', 'SkewKTE', 'BMI', 'Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  80.57810457516342 %\n"
     ]
    }
   ],
   "source": [
    "# Encode the feature values from strings to integers since the sklearn DecisionTreeClassifier only takes numerical values\n",
    "for label in dataset.columns:\n",
    "    dataset[label] = LabelEncoder().fit(dataset[label]).transform(dataset[label])\n",
    "        \n",
    "Tree_model = DecisionTreeClassifier(criterion = \"entropy\",max_depth = 1)\n",
    "\n",
    "X = dataset.drop('Class',axis=1)\n",
    "Y = dataset['Class'].where(dataset['Class']==1,-1)\n",
    "\n",
    "predictions = np.mean(cross_validate(Tree_model,X,Y,cv = 100)['test_score'])\n",
    "\n",
    "print('The accuracy is: ',predictions*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -1\n",
       "1      -1\n",
       "2      -1\n",
       "3      -1\n",
       "4      -1\n",
       "5      -1\n",
       "6      -1\n",
       "7      -1\n",
       "8      -1\n",
       "9      -1\n",
       "10     -1\n",
       "11     -1\n",
       "12     -1\n",
       "13     -1\n",
       "14     -1\n",
       "15     -1\n",
       "16     -1\n",
       "17     -1\n",
       "18     -1\n",
       "19     -1\n",
       "20     -1\n",
       "21     -1\n",
       "22     -1\n",
       "23     -1\n",
       "24     -1\n",
       "25     -1\n",
       "26     -1\n",
       "27     -1\n",
       "28     -1\n",
       "29     -1\n",
       "       ..\n",
       "3506    1\n",
       "3507    1\n",
       "3508    1\n",
       "3509    1\n",
       "3510    1\n",
       "3511    1\n",
       "3512    1\n",
       "3513    1\n",
       "3514    1\n",
       "3515    1\n",
       "3516    1\n",
       "3517    1\n",
       "3518    1\n",
       "3519    1\n",
       "3520    1\n",
       "3521    1\n",
       "3522    1\n",
       "3523    1\n",
       "3524    1\n",
       "3525    1\n",
       "3526    1\n",
       "3527    1\n",
       "3528    1\n",
       "3529    1\n",
       "3530    1\n",
       "3531    1\n",
       "3532    1\n",
       "3533    1\n",
       "3534    1\n",
       "3535    1\n",
       "Name: Class, Length: 3536, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Boosting:\n",
    "    def __init__(self,dataset,T,test_dataset):\n",
    "        self.dataset = dataset\n",
    "        self.T = T\n",
    "        self.test_dataset = test_dataset\n",
    "        self.alphas = None\n",
    "        self.models = None\n",
    "        self.accuracy = []\n",
    "        self.predictions = None\n",
    "    \n",
    "    def fit(self):\n",
    "        # Set the descriptive features and the target feature\n",
    "        X = self.dataset.drop(['Class'],axis=1)\n",
    "        Y = self.dataset['Class'].where(self.dataset['Class']==1,-1)\n",
    "        \n",
    "        # Initialize the weights of each sample with wi = 1/N and create a dataframe where the evaluation is computed\n",
    "        evaluation = pd.DataFrame(Y.copy())\n",
    "        evaluation['weights'] = 1/len(self.dataset) # Set the initial weights w = 1/N\n",
    "        \n",
    "        # Run the boosting algorithm by creating T \"weighted models\"\n",
    "        alphas = [] \n",
    "        models = []\n",
    "        \n",
    "        for t in range(self.T):\n",
    "            # Train the Decision Stump(s)\n",
    "            Tree_model = DecisionTreeClassifier(criterion=\"entropy\",max_depth=1) #depth one --> Decision Stump\n",
    "            \n",
    "            # Train the stumps on weighted datasets where the w depend on the results of previous decision stumps. \n",
    "            # To accomplish that, we use the 'weights' column of the 'evaluation dataframe' together with the \n",
    "            # sample_weight parameter of the fit method.\n",
    "            \n",
    "            model = Tree_model.fit(X,Y,sample_weight=np.array(evaluation['weights'])) \n",
    "            \n",
    "            # Append the single weak classifiers to a list which is later on used to make the weighted decision.\n",
    "            \n",
    "            models.append(model)\n",
    "            predictions = model.predict(X)\n",
    "            score = model.score(X,Y)\n",
    "            \n",
    "            # Add values to the Evaluation DataFrame\n",
    "            Evaluation['predictions'] = predictions\n",
    "            Evaluation['evaluation'] = np.where(Evaluation['predictions'] == Evaluation['target'],1,0)\n",
    "            Evaluation['misclassified'] = np.where(Evaluation['predictions'] != Evaluation['target'],1,0)\n",
    "            \n",
    "            # Calculate the misclassification rate and accuracy\n",
    "            accuracy = sum(Evaluation['evaluation'])/len(Evaluation['evaluation'])\n",
    "            misclassification = sum(Evaluation['misclassified'])/len(Evaluation['misclassified'])\n",
    "            \n",
    "            # Caclulate the error\n",
    "            err = np.sum(Evaluation['weights']*Evaluation['misclassified'])/np.sum(Evaluation['weights'])\n",
    " \n",
    "   \n",
    "            # Calculate the alpha values\n",
    "            alpha = np.log((1-err)/err)\n",
    "            alphas.append(alpha)\n",
    "            \n",
    "            # Update the weights wi --> These updated weights are used in the sample_weight parameter\n",
    "            # for the training of the next decision stump. \n",
    "            Evaluation['weights'] *= np.exp(alpha*Evaluation['misclassified'])\n",
    "            \n",
    "            #print('The Accuracy of the {0}. model is : '.format(t+1),accuracy*100,'%')\n",
    "            #print('The missclassification rate is: ',misclassification*100,'%')\n",
    "        \n",
    "        self.alphas = alphas\n",
    "        self.models = models\n",
    "            \n",
    "    def predict(self):\n",
    "        X_test = self.test_dataset.drop(['target'],axis=1).reindex(range(len(self.test_dataset)))\n",
    "        Y_test = self.test_dataset['target'].reindex(range(len(self.test_dataset))).where(self.dataset['target']==1,-1)\n",
    "    \n",
    "        # With each model in the self.model list, make a prediction \n",
    "        \n",
    "        accuracy = []\n",
    "        predictions = []\n",
    "        \n",
    "        for alpha,model in zip(self.alphas,self.models):\n",
    "            # We use the predict method for the single decisiontreeclassifier models in the list\n",
    "            prediction = alpha*model.predict(X_test) \n",
    "            predictions.append(prediction)\n",
    "            self.accuracy.append(np.sum(np.sign(np.sum(np.array(predictions),axis=0))==Y_test.values)/len(predictions[0]))\n",
    "            \n",
    "            '''Describing the above line:\n",
    "            \n",
    "            Goal: Create a list of accuracies which can be used to plot the accuracy against the number of base learners \n",
    "            used for the model.\n",
    "            \n",
    "            1. np.array(predictions): this is the array which contains the predictions of the single models. \n",
    "            shape 8124xn, looks like [[0.998,0.87,...0.87...],[...],[...],[0.99,1.23,...,1.05,0,99...]] \n",
    "            \n",
    "            2. np.sum(np.array(predictions),axis=0): Sums up the first elements of the lists, that is 0,998+...+...+0.99. \n",
    "            This is done as the formula for the prediction wants the sum of the predictions of all models for each \n",
    "            instance in the dataset. For example if you have 3 models then the predictions array has the shape 8124x3 \n",
    "            (a table with 3 columns and 8124 rows). The nth column contains the predictions for the nth model. \n",
    "            The results from column/model n-1 alter the weights of the nth model. \n",
    "            \n",
    "            3. np.sign(np.sum(np.array(predictions),axis=0)): Since the test target data are elements of {-1,1} and the \n",
    "            prediction should be the same format --> use the sign function. So each column in the accuracy array \n",
    "            looks like [-0.998,1.002,1.24,...,-0.89] and each element represents the combined and weighted prediction of \n",
    "            all models up this column. For example, in the nth column and for the ith instance we find the value -0.989, \n",
    "            this value represents the ith instance of a weighted prediction of a boosted model with n base learners.\n",
    "            I'm nterested in the sign of these combined predictions. A high positive value defines a likely positive \n",
    "            classification, a high negative value defines a likely negative or opposite) classification. \n",
    "            \n",
    "            4. np.sum(np.sign(np.sum(np.array(predictions),axis=0))==Y_test.values)/len(predictions[0]): \n",
    "            With the last step we transform the array into the shape 8124x1 where the instances are elements {-1,1} \n",
    "            so that I can compare these predictions with our targets. The target feature array also has shape 8124x1. \n",
    "            The comparison is done with “ == Y_test.value ” . As a result you get an array of shape 8124x1 where the i\n",
    "            nstances are elements of {True,False};  True if the prediction matches the target feature value and False if not.\n",
    "            Dividing the sum of 1s (True predictions) by the total length with “len(predictions[0])” returns a fraction \n",
    "            of correct predictions for a  %.\n",
    "            \n",
    "            5. full line: add the result to the self.accuracy list. \n",
    "            This list has the shape n x 1; for a model with 5 base learners this list has 5 entries where the 5th entry \n",
    "            represents the accuracy of the model when all 5 base learners are combined etc.''' \n",
    "\n",
    "        self.predictions = np.sign(np.sum(np.array(predictions),axis=0))\n",
    "   \n",
    "        \n",
    "        \n",
    "#Plot the accuracy of the model against the number of stumps (weak classifiers) used\n",
    "\n",
    "number_of_base_learners = 50\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax0 = fig.add_subplot(111)\n",
    "for i in range(number_of_base_learners):\n",
    "    model = Boosting(dataset,i,dataset)\n",
    "    model.fit()\n",
    "    model.predict()\n",
    "ax0.plot(range(len(model.accuracy)),model.accuracy,'-b')\n",
    "ax0.set_xlabel('# models used for Boosting ')\n",
    "ax0.set_ylabel('accuracy')\n",
    "print('With a number of ',number_of_base_learners,'base models we receive an accuracy of ',model.accuracy[-1]*100,'%')    \n",
    "                 \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
